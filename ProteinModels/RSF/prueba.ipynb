{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/tenerife/mambaforge/envs/lungAmbpy3/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "censoring survival function is zero at one or more time points",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 307\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m, y_pred)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# Compute time-dependent AUC\u001b[39;00m\n\u001b[0;32m--> 307\u001b[0m auc_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcumulative_dynamic_auc\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_points\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tenerife/mambaforge/envs/lungAmbpy3/lib/python3.8/site-packages/sksurv/metrics.py:457\u001b[0m, in \u001b[0;36mcumulative_dynamic_auc\u001b[0;34m(survival_train, survival_test, estimate, times, tied_tol)\u001b[0m\n\u001b[1;32m    455\u001b[0m cens \u001b[38;5;241m=\u001b[39m CensoringDistributionEstimator()\n\u001b[1;32m    456\u001b[0m cens\u001b[38;5;241m.\u001b[39mfit(survival_train)\n\u001b[0;32m--> 457\u001b[0m ipcw \u001b[38;5;241m=\u001b[39m \u001b[43mcens\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_ipcw\u001b[49m\u001b[43m(\u001b[49m\u001b[43msurvival_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;66;03m# expand arrays to (n_samples, n_times) shape\u001b[39;00m\n\u001b[1;32m    460\u001b[0m test_time \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbroadcast_to(test_time[:, np\u001b[38;5;241m.\u001b[39mnewaxis], (n_samples, n_times))\n",
      "File \u001b[0;32m~/tenerife/mambaforge/envs/lungAmbpy3/lib/python3.8/site-packages/sksurv/nonparametric.py:583\u001b[0m, in \u001b[0;36mCensoringDistributionEstimator.predict_ipcw\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    580\u001b[0m Ghat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_proba(time[event])\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (Ghat \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m)\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m--> 583\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcensoring survival function is zero at one or more time points\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    585\u001b[0m weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(time\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    586\u001b[0m weights[event] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m Ghat\n",
      "\u001b[0;31mValueError\u001b[0m: censoring survival function is zero at one or more time points"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score, confusion_matrix, mean_squared_error, mean_absolute_error\n",
    "from sksurv.metrics import concordance_index_censored, brier_score, cumulative_dynamic_auc\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import glob\n",
    "from sklearn.inspection import permutation_importance\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import shap\n",
    "from sksurv.nonparametric import kaplan_meier_estimator\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "seed = 1\n",
    "\n",
    "# Define custom scoring function for the concordance index\n",
    "def concordance_scorer(estimator, X, y):\n",
    "    # Extract event indicator and time from the structured array\n",
    "    event_indicator, event_time = y[\"Cancer_Status\"], y[\"TimeYears_CT_blood\"]\n",
    "    \n",
    "    # Predict risk scores\n",
    "    risk_scores = estimator.predict(X)\n",
    "    \n",
    "    # Calculate concordance index\n",
    "    concordance = concordance_index_censored(event_indicator, event_time, risk_scores)[0]\n",
    "    return concordance\n",
    "\n",
    "def brier_score_at_time(estimator, X, y, time_point=0):\n",
    "    \"\"\"Custom Brier Score metric at a specific time point for use in GridSearchCV.\"\"\"\n",
    "    surv_funcs = estimator.predict_survival_function(X)  # Get survival functions for the predictions\n",
    "    test_estimates = np.array([fn(time_point) for fn in surv_funcs])  # Survival prob. at 1 year\n",
    "    brier_score_1yr = brier_score(y_train, y, test_estimates, [time_point])[1][0]  # Brier Score at 1 year\n",
    "    return -brier_score_1yr  # Negative for maximizing in GridSearchCV\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "n_folds=3\n",
    "path_to_save_results = '/home/ubuntu/tenerife/data/LungAmbition/Proteinas/ResultsBaselines_BM/RSF'\n",
    "path_to_save_plots = os.path.join(path_to_save_results, 'plots')\n",
    "path_to_fold_division_folder = f'/home/ubuntu/tenerife/data/ZZ_githubRepos/LungAmbition/Data_stratified_split/folds-def_{n_folds}folds'\n",
    "keep_false_positives_as_separate_test = True\n",
    "# create path_to_save_plots if it does not exist\n",
    "if not os.path.exists(path_to_save_plots):\n",
    "    os.makedirs(path_to_save_plots)\n",
    "\n",
    "name_file= \"ROS_RSF_proteins_6nov2024_correctedTo5YearsCensorship\"\n",
    "if keep_false_positives_as_separate_test:\n",
    "    name_file= name_file + \"_keep_false_positives_as_separate_test\"\n",
    "sys.stdout=open(os.path.join(path_to_save_results, \"run_out_\"+name_file+\"_5fold.txt\"),'w')\n",
    "# save prints in a txt file\n",
    "original_stdout = sys.stdout\n",
    "\n",
    "df_merged = pd.read_csv('/home/ubuntu/tenerife/data/LungAmbition/Excels_merged/LungAmbitionMergedAll7nov2024.csv')\n",
    "# ignore columns 'ID_imagingData', 'Group', 'Cancer_Status', 'TimeYears_CT_blood',\n",
    "# 'Diff_Diag_Blood_TimeYears_CT_blood', 'LastFollow_upTimeYears_CT_blood', 'Age', 'Sex', \n",
    "# 'Body_mass_index','Smoking_status', 'Years_smoked', 'Smoking_pack_years', \n",
    "# 'Family_history_lung_cancer','Personal_history_cancer', 'Stage_category','NRRD_File', 'SEG_Files'\n",
    "# in df_merged\n",
    "# for correct handling of TimeYears_CT_blood, if TimeYears_CT_blood is over 5 years, change it to 5 years\n",
    "# in df_merged column TimeYears_CT_blood change to 5 if its over 5 years for patients that are not in Lung_Cancer group\n",
    "df_merged.loc[(df_merged['TimeYears_CT_blood'] == 5) & (df_merged['Group'] != 'Lung_Cancer'), 'TimeYears_CT_blood'] = 6\n",
    "y_target = df_merged[['ID_proteinData', 'Cancer_Status', 'TimeYears_CT_blood']]\n",
    "columns_to_drop=['ID_imagingData', 'Group', 'Cancer_Status', \n",
    "                'TimeYears_blood', 'TimeMonths_blood', 'TimeYears_CT_blood', 'TimeMonths_CT_blood',\n",
    "                'Diff_Diag_Blood_TimeYears', 'LastFollow_upTimeYears', \n",
    "                'Age', 'Sex', 'Body_mass_index','Smoking_status', 'Years_smoked', 'Smoking_pack_years',\n",
    "                'Family_history_lung_cancer','Personal_history_cancer', 'Stage_category',\n",
    "                'NRRD_File', 'SEG_Files']\n",
    "# for correct handling of TimeYears_CT_blood, if TimeYears_CT_blood is over 5 years, change it to 5 years\n",
    "# in df_merged column TimeYears_CT_blood change to 5 if its over 5 years for patients that are not in Lung_Cancer group\n",
    "\n",
    "X = df_merged.drop(columns=columns_to_drop)\n",
    "if keep_false_positives_as_separate_test:\n",
    "    # create list to store wrong predicted false positives\n",
    "    list_ID_wrong_predicted_false_positives = []\n",
    "    # save false_positive_metrics in df\n",
    "\n",
    "# save best metrics for each fold\n",
    "fold_metrics_df = pd.DataFrame(columns=['Fold', 'Concordance_Index', 'Integrated_Brier_Score',\n",
    "                                        'AUC_at_0_Years', 'Accuracy_at_0_Years', 'Balanced_Accuracy_at_0_Years', 'Precision_at_0_Years', 'Recall_at_0_Years', 'F1_Score_at_0_Years', 'Specificity_at_0_Years', 'NPV_at_0_Years',\n",
    "                                        'AUC_at_1_Years', 'Accuracy_at_1_Years', 'Balanced_Accuracy_at_1_Years', 'Precision_at_1_Years', 'Recall_at_1_Years', 'F1_Score_at_1_Years', 'Specificity_at_1_Years', 'NPV_at_1_Years',\n",
    "                                        'AUC_at_2_Years', 'Accuracy_at_2_Years', 'Balanced_Accuracy_at_2_Years', 'Precision_at_2_Years', 'Recall_at_2_Years', 'F1_Score_at_2_Years', 'Specificity_at_2_Years', 'NPV_at_2_Years',\n",
    "                                        'AUC_at_3_Years', 'Accuracy_at_3_Years', 'Balanced_Accuracy_at_3_Years', 'Precision_at_3_Years', 'Recall_at_3_Years', 'F1_Score_at_3_Years', 'Specificity_at_3_Years', 'NPV_at_3_Years',\n",
    "                                        'AUC_at_4_Years', 'Accuracy_at_4_Years', 'Balanced_Accuracy_at_4_Years', 'Precision_at_4_Years', 'Recall_at_4_Years', 'F1_Score_at_4_Years', 'Specificity_at_4_Years', 'NPV_at_4_Years',\n",
    "                                        'AUC_at_5_Years', 'Accuracy_at_5_Years', 'Balanced_Accuracy_at_5_Years', 'Precision_at_5_Years', 'Recall_at_5_Years', 'F1_Score_at_5_Years', 'Specificity_at_5_Years', 'NPV_at_5_Years'])\n",
    "# save top features for each fold\n",
    "top_features_df_list = []\n",
    "\n",
    "# iterate over each file in path_to_fold_division_folder\n",
    "# Use glob to find all CSV files in the folder\n",
    "for file_path in sorted(glob.glob(os.path.join(path_to_fold_division_folder, 'id2splitfold_*.csv'))):\n",
    "    print(\"Reading file:\", file_path)\n",
    "    # Extract the fold number from the filename\n",
    "    fold = int(os.path.basename(file_path).split('_')[-1].split('.')[0])\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df_fold = pd.read_csv(file_path)\n",
    "    # rename GroupUpdated column into Group in df_fold\n",
    "    df_fold.rename(columns={'GroupUpdated': 'Group'}, inplace=True)\n",
    "    # drop columns where Group == Control\n",
    "    df_fold = df_fold[df_fold['Group'] != 'Control'] ### uncomment this for BC vs LC\n",
    "    # rename in Group column IndeterminatePreLungCancer to Lung_Cancer in df_fold\n",
    "    df_fold.loc[df_fold['Group'] == 'IndeterminatePreLungCancer', 'Group'] = 'Lung_Cancer'\n",
    "    print(df_fold[df_fold['Group']=='Lung_Cancer'].TimeYears_CT_blood.value_counts())\n",
    "    # next line is not necfcessary, but we keep here for completion\n",
    "    df_fold.loc[(df_fold['TimeYears_CT_blood'] == 5) & (df_fold['Group'] != 'Lung_Cancer'), 'TimeYears_CT_blood'] = 6\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Fold {fold + 1}:\")\n",
    "    # based on df_fold.split (train, test, val, test_false_positive) asign in df_merged the corresponding fold\n",
    "    # Get the ID_proteinData values for each split in df_fold\n",
    "    train_ids = df_fold[df_fold['split'] == 'train']['ID_proteinData'].tolist()\n",
    "    val_ids = df_fold[df_fold['split'] == 'val']['ID_proteinData'].tolist()\n",
    "    test_ids = df_fold[df_fold['split'] == 'test']['ID_proteinData'].tolist()\n",
    "    if keep_false_positives_as_separate_test:\n",
    "        false_positive_ids = df_fold[df_fold['split'] == 'test_false_positive']['ID_proteinData'].tolist()\n",
    "        # Get the corresponding rows from df_merged\n",
    "        X_test_false_positives = df_merged[df_merged['ID_proteinData'].isin(false_positive_ids)]\n",
    "        y_test_false_positives = df_merged[df_merged['ID_proteinData'].isin(false_positive_ids)][['Cancer_Status', 'TimeYears_CT_blood']]\n",
    "        ID_false_positives = X_test_false_positives['ID_proteinData'].values\n",
    "        X_test_false_positives = X_test_false_positives.drop(columns=columns_to_drop)\n",
    "        X_test_false_positives = X_test_false_positives.drop(columns=['ID_proteinData'])\n",
    "        print(\"False positives data:\", X_test_false_positives.shape, y_test_false_positives.shape, \n",
    "              \"Test false positives:\", len(y_test_false_positives[y_test_false_positives.Cancer_Status == 0]))\n",
    "    else:\n",
    "        # include false positives in test\n",
    "        test_ids = test_ids + df_fold[df_fold['split'] == 'test_false_positive']['ID_proteinData'].tolist()\n",
    "\n",
    "    # Filter X and y_target based on these lists of IDs\n",
    "    X_train = X[X['ID_proteinData'].isin(train_ids)].drop(columns=['ID_proteinData'])\n",
    "    X_val = X[X['ID_proteinData'].isin(val_ids)].drop(columns=['ID_proteinData'])\n",
    "    X_test = X[X['ID_proteinData'].isin(test_ids)].drop(columns=['ID_proteinData'])\n",
    "    # ver que hacer con false_positives, eliminar ID_proteinData\n",
    "    y_train = y_target[y_target['ID_proteinData'].isin(train_ids)].drop(columns=['ID_proteinData'])\n",
    "    y_val = y_target[y_target['ID_proteinData'].isin(val_ids)].drop(columns=['ID_proteinData'])\n",
    "    y_test = y_target[y_target['ID_proteinData'].isin(test_ids)].drop(columns=['ID_proteinData'])\n",
    "\n",
    "    print(\"Training data:\", X_train.shape, y_train.shape, \n",
    "          \"Benigns train:\", len(y_train[y_train.Cancer_Status == 0]), \"Lung cancer patients train:\", len(y_train[y_train.Cancer_Status == 1]))\n",
    "    print(\"Validation data:\", X_val.shape, y_val.shape, \n",
    "          \"Benigns val:\", len(y_val[y_val.Cancer_Status == 0]), \"Lung cancer patients val:\", len(y_val[y_val.Cancer_Status == 1]))\n",
    "    print(\"Test data:\", X_test.shape, y_test.shape, \n",
    "          \"Benigns test:\", len(y_test[y_test.Cancer_Status == 0]), \"Lung cancer patients test:\", len(y_test[y_test.Cancer_Status == 1]))\n",
    "    print(\"Number of samples per class in y_train\")\n",
    "    print(y_train.Cancer_Status.value_counts())\n",
    "    print(\"Number of samples per class in y_test\")\n",
    "    print(y_test.Cancer_Status.value_counts())\n",
    "    print(\"Number of samples per class in y_val\")\n",
    "    print(y_val.Cancer_Status.value_counts())\n",
    "    # join X_val in X_train and y_val in y_train ### OJO esto revisar!!\n",
    "    X_train = pd.concat([X_train, X_val], axis=0)\n",
    "    y_train = pd.concat((y_train, y_val), axis=0)\n",
    "    # print max TimeYears_CT_blood in y_train\n",
    "    print(\"Max TimeYears_CT_blood in y_train:\", y_train['TimeYears_CT_blood'].max())\n",
    "    print(\"Max TimeYears_CT_blood in y_test:\", y_test['TimeYears_CT_blood'].max())\n",
    "    # print training data after joining with validation data\n",
    "    print(\"Training data after joining with validation data:\", X_train.shape, y_train.shape, \"Benign patients train:\", len(y_train[y_train['Cancer_Status'] == False]), \"Lung cancer patients train:\", len(y_train[y_train['Cancer_Status'] == True]))\n",
    "    print(\"Lung cancer patients (TimeYears_CT_blood = 0, before duplicating):\", len(y_train[(y_train['Cancer_Status'] == 1) & (y_train['TimeYears_CT_blood'] == 0)]))\n",
    "    print(\"Lung cancer patients (TimeYears_CT_blood > 0, before duplicating):\", len(y_train[(y_train['Cancer_Status'] == 1) & (y_train['TimeYears_CT_blood'] > 0)]))\n",
    "    print(\"Benign participants:\", len(y_train[y_train['Cancer_Status'] == 0]))\n",
    "    # combine X_train and y_train to apply oversampling and oversample only the lung cancer class\n",
    "    X_y_train_combined = pd.concat([X_train, y_train], axis=1)\n",
    "    # drop column Cancer_Status in X_y_train_combined\n",
    "    y_train_CancerStatus = X_y_train_combined['Cancer_Status'].values\n",
    "    # duplicate all LC patients to improve learning\n",
    "    # in X_y_train_combined_TimeYears_CT_blood repeat twice rows where LungCancer == 1 and TimeYears_CT_blood == 0\n",
    "    filtered_rows = X_y_train_combined[\n",
    "        (X_y_train_combined['Cancer_Status'] == 1)]\n",
    "\n",
    "    # Repeat these rows twice\n",
    "    resampled_rows = pd.concat([filtered_rows], ignore_index=True)\n",
    "\n",
    "    # Append to the original DataFrame\n",
    "    X_y_train_resampled_TimeYears_CT_blood = pd.concat(\n",
    "        [X_y_train_combined, resampled_rows], ignore_index=True\n",
    "    )\n",
    "    X_train_resampled = X_y_train_resampled_TimeYears_CT_blood.drop(columns=['TimeYears_CT_blood', 'Cancer_Status'])\n",
    "    y_train_resampled = X_y_train_resampled_TimeYears_CT_blood[['TimeYears_CT_blood', 'Cancer_Status']]\n",
    "    print(\"Training data after duplicating LC patients:\", X_train_resampled.shape, y_train_resampled.shape)\n",
    "    # rename X_train_resampled to X_train and y_train_resampled to y_train\n",
    "    X_train = X_train_resampled\n",
    "    y_train = y_train_resampled\n",
    "    print(\"Non-lung cancer patients (All years):\", len(y_train[y_train == 0]))\n",
    "    print(\"Lung cancer patients (TimeYears_CT_blood = 0):\", len(y_train[(y_train['Cancer_Status'] == 1) & (y_train['TimeYears_CT_blood'] == 0)]))\n",
    "    print(\"Lung cancer patients (TimeYears_CT_blood > 0):\", len(y_train[(y_train['Cancer_Status'] == 1) & (y_train['TimeYears_CT_blood'] > 0)]))\n",
    "    print(\"Benign participants:\", len(y_train[y_train['Cancer_Status'] == 0]))\n",
    "\n",
    "    # # print(\"y_train_CancerStatus after conversion:\", y_train_CancerStatus)\n",
    "    # X_y_train_combined_TimeYears_CT_blood = X_y_train_combined.drop(columns=['Cancer_Status'])\n",
    "\n",
    "    # # Define RandomOverSampler to target the minority class in `Cancer_Status`\n",
    "    # ros = RandomOverSampler(sampling_strategy='minority', random_state=seed)\n",
    "\n",
    "    # # Apply oversampling on the combined DataFrame\n",
    "    # X_y_train_resampled_TimeYears_CT_blood, y_train_resampled_CancerStatus = ros.fit_resample(X_y_train_combined_TimeYears_CT_blood, y_train_CancerStatus)\n",
    "    # # print(\"y_train_resampledCancerStatus after conversion:\", y_train_resampled_CancerStatus)\n",
    "    # # Split the resampled data into X and y parts\n",
    "    # y_train_resampled = pd.DataFrame(y_train_resampled_CancerStatus, columns=['Cancer_Status'])\n",
    "    # # include in y_train_resampled the TimeYears_CT_blood\n",
    "    # y_train_resampled['TimeYears_CT_blood'] = X_y_train_resampled_TimeYears_CT_blood['TimeYears_CT_blood']\n",
    "    # X_train_resampled = X_y_train_resampled_TimeYears_CT_blood.drop(columns=['TimeYears_CT_blood'])  # All columns except 'TimeYears_CT_blood'\n",
    "\n",
    "    # print(\"Training data after oversampling:\", X_train_resampled.shape, y_train_resampled.shape)\n",
    "    # print(\"Non lung cancer patients train:\", len(y_train_resampled[y_train_resampled['Cancer_Status'] == False]))\n",
    "    # print(\"Lung cancer patients train:\", len(y_train_resampled[y_train_resampled['Cancer_Status'] == True]))\n",
    "\n",
    "    # # rename X_train_resampled to X_train and y_train_resampled to y_train\n",
    "    # X_train = X_train_resampled\n",
    "    # y_train = y_train_resampled\n",
    "    # oversample lung cancer at year 0 class\n",
    "    # Identify patients where `TimeYears_CT_blood == 0`\n",
    "        \n",
    "    event = y_train[\"Cancer_Status\"]  # Structured array access\n",
    "    time = y_train[\"TimeYears_CT_blood\"]  # Structured array access\n",
    "    \n",
    "    # convert y to structured array with the first field being a binary class event indicator and the second field the time of the event/censoring\n",
    "    y_train = np.array([(status, time) for status, time in y_train.values], dtype=[('Cancer_Status', 'bool'), ('TimeYears_CT_blood', 'float')])\n",
    "    y_test = np.array([(status, time) for status, time in y_test.values], dtype=[('Cancer_Status', 'bool'), ('TimeYears_CT_blood', 'float')])\n",
    "    \n",
    "    # scale the data using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    # print shapes of X_train and X_test\n",
    "    print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)\n",
    "    print(\"X_test shape:\", X_test.shape, \"y_test shape:\", y_test.shape)\n",
    "    # train RSF, first find the best hyperparameters through a grid search cv,\n",
    "    # then train the model with the best hyperparameters\n",
    "    # parameters to search\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [100, 200, 300, 400],\n",
    "        \"max_depth\": [2, 3, 4, 5],\n",
    "        \"min_samples_split\": [5, 6, 7],\n",
    "        \"min_samples_leaf\": [4, 5],\n",
    "        \"max_features\": ['sqrt', 150, 200, 250, 'log2'],\n",
    "    }\n",
    "    # random forest classifier\n",
    "    rsf = RandomSurvivalForest(random_state=seed)\n",
    "    # grid search cv\n",
    "    # Set up GridSearchCV with validation\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=rsf,\n",
    "        param_grid=param_grid,\n",
    "        cv=KFold(n_splits=3, shuffle=True, random_state=seed),\n",
    "        n_jobs=-1,\n",
    "        verbose=0,\n",
    "        scoring={'concordance': concordance_scorer, 'brier_0yr': brier_score_at_time},\n",
    "        refit='brier_0yr'  # You can refit on the metric that prioritizes your objective\n",
    "    )\n",
    "    # sample_weights = compute_sample_weight(class_weight='balanced', y=(event.astype(bool)) & (time == 0))\n",
    "    # Fit the grid search on training data\n",
    "    grid_search.fit(X_train, y_train)#, sample_weight=sample_weights)\n",
    "\n",
    "    # Print the best hyperparameters\n",
    "    print(\"Best hyperparameters:\")\n",
    "    print(grid_search.best_params_)\n",
    "    best_score = grid_search.best_score_\n",
    "    print(f\"Best Brier Score at 0 year: {-best_score}\")\n",
    "    # print(\"Concordance Index scores for each parameter set:\\n\", grid_search.cv_results_['mean_test_concordance'])\n",
    "    # Use the best estimator to train the model\n",
    "    best_rsf = grid_search.best_estimator_\n",
    "    best_rsf.fit(X_train, y_train)#, sample_weight=sample_weights)\n",
    "    \n",
    "    # Predict risk scores for train and validation sets\n",
    "    train_risk_scores = best_rsf.predict(X_train)\n",
    "    # Concordance Index\n",
    "    train_concordance = concordance_index_censored(y_train[\"Cancer_Status\"], y_train[\"TimeYears_CT_blood\"], train_risk_scores)[0]\n",
    "    # Print metrics for train and validation sets\n",
    "    print(\"Metrics in train:\")\n",
    "    print(f\"Concordance Index: {train_concordance}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # predict in test\n",
    "    y_pred = best_rsf.predict(X_test)\n",
    "\n",
    "    # Calculate the concordance index\n",
    "    concordance = concordance_index_censored(y_test[\"Cancer_Status\"], y_test[\"TimeYears_CT_blood\"], y_pred)[0]\n",
    "\n",
    "    # Predict the survival functions for each sample in the training set\n",
    "    surv_funcs = best_rsf.predict_survival_function(X_test)\n",
    "    # output is a is a list of survival functions, one for each sample in X_test. \n",
    "    # Each survival function provides the probability of survival.\n",
    "    # These probabilities range from 1 (100% survival) at the start of the study period \n",
    "    # down to lower values as time progresses, representing the likelihood that the event \n",
    "    # has not yet occurred by a given time.\n",
    "\n",
    "    # Compute censoring survival function\n",
    "    time_censoring, survival_censoring = kaplan_meier_estimator(event= y_train[\"Cancer_Status\"], time_exit=y_train[\"TimeYears_CT_blood\"])\n",
    "\n",
    "    # Plot censoring survival function\n",
    "    plt.step(time_censoring, survival_censoring, where=\"post\", label=\"Censoring Survival Function\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Survival Probability\")\n",
    "    plt.title(\"Kaplan-Meier Censoring Survival Curve\")\n",
    "    plt.savefig(os.path.join(path_to_save_plots, f\"KM_Censoring_Surv_fold_{fold+1}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # print(\"surv_funcs:\", surv_funcs)\n",
    "    # time_points = [0, 1, 2, 3, 4, 5]  # Specify the time points at which to calculate the Brier score\n",
    "    time_points = [float(t) for t in [0, 1, 2, 3, 4, 5]]\n",
    "    print(f\"Min time: {y_test['TimeYears_CT_blood'].min()}, Max time: {y_test['TimeYears_CT_blood'].max()}\")\n",
    "    print(\"y_pred\", y_pred)\n",
    "    # Compute time-dependent AUC\n",
    "    auc_scores = cumulative_dynamic_auc(y_train, y_test, y_pred, time_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([( True, 0.), ( True, 0.), ( True, 0.), ( True, 0.), ( True, 0.),\n",
       "       ( True, 0.), ( True, 0.), ( True, 0.), ( True, 0.), ( True, 0.),\n",
       "       ( True, 0.), ( True, 0.), ( True, 0.), ( True, 0.), ( True, 0.),\n",
       "       ( True, 0.), ( True, 0.), ( True, 0.), ( True, 0.), ( True, 0.),\n",
       "       ( True, 0.), ( True, 0.), ( True, 0.), ( True, 0.), ( True, 0.),\n",
       "       ( True, 0.), ( True, 0.), ( True, 0.), ( True, 0.), ( True, 0.),\n",
       "       ( True, 0.), ( True, 0.), ( True, 0.), ( True, 0.), ( True, 0.),\n",
       "       ( True, 0.), ( True, 0.), ( True, 0.), ( True, 0.), ( True, 0.),\n",
       "       ( True, 1.), ( True, 1.), ( True, 1.), ( True, 1.), ( True, 1.),\n",
       "       ( True, 1.), (False, 1.), (False, 1.), ( True, 1.), (False, 1.),\n",
       "       (False, 1.), (False, 1.), (False, 1.), (False, 1.), (False, 1.),\n",
       "       ( True, 1.), (False, 1.), ( True, 1.), (False, 1.), ( True, 1.),\n",
       "       ( True, 1.), (False, 1.), ( True, 1.), (False, 1.), (False, 1.),\n",
       "       (False, 1.), ( True, 1.), ( True, 1.), ( True, 1.), ( True, 1.),\n",
       "       ( True, 1.), (False, 1.), (False, 1.), (False, 1.), ( True, 1.),\n",
       "       ( True, 1.), ( True, 1.), (False, 1.), ( True, 1.), ( True, 1.),\n",
       "       ( True, 1.), ( True, 0.), ( True, 0.), ( True, 0.), ( True, 0.),\n",
       "       ( True, 0.), (False, 1.), ( True, 1.), (False, 1.), ( True, 1.),\n",
       "       ( True, 1.), ( True, 1.), ( True, 1.), ( True, 1.), ( True, 1.),\n",
       "       ( True, 1.), (False, 1.), (False, 1.), ( True, 1.), (False, 1.),\n",
       "       (False, 1.), (False, 1.), (False, 1.), (False, 1.), (False, 1.),\n",
       "       ( True, 1.), (False, 1.), ( True, 1.), (False, 1.), ( True, 1.),\n",
       "       ( True, 1.), (False, 1.), ( True, 1.), (False, 1.), (False, 1.),\n",
       "       (False, 1.), ( True, 1.), ( True, 1.), ( True, 1.), ( True, 1.),\n",
       "       ( True, 1.), (False, 1.), (False, 1.), (False, 1.), ( True, 1.),\n",
       "       ( True, 1.), ( True, 1.), (False, 1.), ( True, 1.), ( True, 1.),\n",
       "       ( True, 1.), (False, 1.), ( True, 1.), (False, 1.), ( True, 1.)],\n",
       "      dtype=[('Cancer_Status', '?'), ('TimeYears_CT_blood', '<f8')])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(False, 6.), (False, 6.), (False, 6.), (False, 6.), (False, 6.),\n",
       "       (False, 6.), (False, 6.), (False, 6.), (False, 6.), (False, 6.),\n",
       "       (False, 6.), (False, 6.), (False, 6.), (False, 6.), (False, 6.),\n",
       "       (False, 6.), (False, 6.), (False, 6.), (False, 6.), (False, 6.),\n",
       "       (False, 6.), (False, 6.), (False, 6.), ( True, 1.), ( True, 1.),\n",
       "       ( True, 2.), ( True, 0.), ( True, 0.), ( True, 5.), ( True, 3.),\n",
       "       ( True, 4.), ( True, 4.), ( True, 4.), ( True, 0.), ( True, 3.),\n",
       "       ( True, 0.), ( True, 0.), ( True, 0.), ( True, 0.), ( True, 0.),\n",
       "       ( True, 0.), ( True, 0.), ( True, 0.), ( True, 2.), ( True, 1.)],\n",
       "      dtype=[('Cancer_Status', '?'), ('TimeYears_CT_blood', '<f8')])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lungAmbpy3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
