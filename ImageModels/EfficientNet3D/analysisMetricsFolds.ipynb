{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Analysis metrics DenseNet 3D\n",
    "df_fold_0 = pd.read_csv('/home/ubuntu/tenerife/data/LungAmbition/Images/ResultsBaselines_BMY0/3D/EfficientNet_crop32/Results/metrics_df_test_fold0_EfficientNetBNb0_crop32_smallDataAug_1april25.csv')\n",
    "df_fold_1 = pd.read_csv('/home/ubuntu/tenerife/data/LungAmbition/Images/ResultsBaselines_BMY0/3D/EfficientNet_crop32/Results/metrics_df_test_fold1_EfficientNetBNb0_crop32_smallDataAug_1april25_fold1.csv')\n",
    "df_fold_2 = pd.read_csv('/home/ubuntu/tenerife/data/LungAmbition/Images/ResultsBaselines_BMY0/3D/EfficientNet_crop32/Results/metrics_df_test_fold2_EfficientNetBNb0_crop32_smallDataAug_2april25_fold2.csv')\n",
    "# merge df_fold_0 and df_fold_12\n",
    "fold_metrics_df = pd.concat([df_fold_0, df_fold_1, df_fold_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC: 0.85565239913066 Std AUC: 0.039565180100682364\n",
      "Mean Accuracy: 0.8029903717759505 Std Accuracy: 0.03706852501685631\n",
      "Mean Balanced accuracy: 0.7594816616555747 Std Balanced accuracy: 0.0868531183536011\n",
      "Mean Precision: 0.7380952380952381 Std Precision: 0.05408484138857407\n",
      "Mean Recall/Sensitivity: 0.6368816368816369 Std Recall: 0.2366759331912282\n",
      "Mean F1-score: 0.6591942820012996 Std F1-score: 0.1378800725488593\n",
      "Mean Specificity: 0.8820816864295126 Std Specificity: 0.06714522007002448\n",
      "Mean NPV: 0.8423396526844802 Std NPV: 0.07536229900450296\n"
     ]
    }
   ],
   "source": [
    "mean_auc = fold_metrics_df['AUC'].mean()\n",
    "std_auc = fold_metrics_df['AUC'].std()\n",
    "mean_accuracy = fold_metrics_df['Accuracy'].mean()\n",
    "std_accuracy = fold_metrics_df['Accuracy'].std()\n",
    "mean_balanced_accuracy = fold_metrics_df['Bal_accuracy'].mean()\n",
    "std_balanced_accuracy = fold_metrics_df['Bal_accuracy'].std()\n",
    "mean_precision = fold_metrics_df['Precision'].mean()\n",
    "std_precision = fold_metrics_df['Precision'].std()\n",
    "mean_recall = fold_metrics_df['Sensitivity'].mean()\n",
    "std_recall = fold_metrics_df['Sensitivity'].std()\n",
    "mean_f1 = fold_metrics_df['F1-score'].mean()\n",
    "std_f1 = fold_metrics_df['F1-score'].std()\n",
    "mean_specificity = fold_metrics_df['Specificity'].mean()\n",
    "std_specificity = fold_metrics_df['Specificity'].std()\n",
    "mean_NPV = fold_metrics_df['NPV'].mean()\n",
    "std_NPV = fold_metrics_df['NPV'].std()\n",
    "# print metrics\n",
    "print(\"Mean AUC:\", mean_auc, \"Std AUC:\", std_auc)\n",
    "print(\"Mean Accuracy:\", mean_accuracy, \"Std Accuracy:\", std_accuracy)\n",
    "print(\"Mean Balanced accuracy:\", mean_balanced_accuracy, \"Std Balanced accuracy:\", std_balanced_accuracy)\n",
    "print(\"Mean Precision:\", mean_precision, \"Std Precision:\", std_precision)\n",
    "print(\"Mean Recall/Sensitivity:\", mean_recall, \"Std Recall:\", std_recall)\n",
    "print(\"Mean F1-score:\", mean_f1, \"Std F1-score:\", std_f1)\n",
    "print(\"Mean Specificity:\", mean_specificity, \"Std Specificity:\", std_specificity)\n",
    "print(\"Mean NPV:\", mean_NPV, \"Std NPV:\", std_NPV)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lungAmbpy3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
