{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of false positives: 5\n",
      "================================================================================\n",
      "Fold 1:\n",
      "Train, total benign nodules 40 lung cancer 18\n",
      "Val, total benign nodules 5 lung cancer 2\n",
      "Test, total benign nodules 23 lung cancer 11\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Author: Miriam Cobo Cano\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "import datetime\n",
    "import numpy as np\n",
    "from model.train import train_model\n",
    "from model.test import val_model, test_model\n",
    "import pandas as pd\n",
    "from sklearn.utils import class_weight\n",
    "import logging\n",
    "from model.plots import plot_training_metrics\n",
    "sys.path.append('/home/ubuntu/tenerife/data/ZZ_githubRepos/baselinesLungAmbition/ImageModels/LoadData')\n",
    "from load_LungAmbition3D_test_data import load_lungAmbition\n",
    "# for paralelization\n",
    "import torch.optim as optim\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import matplotlib.pyplot as plt\n",
    "import psutil\n",
    "import ast\n",
    "from monai.networks.nets import DenseNet121\n",
    "torch.cuda.empty_cache()\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "from types import SimpleNamespace\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "n_folds=3\n",
    "path_to_folds_csv = f'/home/ubuntu/tenerife/data/ZZ_githubRepos/LungAmbition/Data_stratified_split/folds-def_{n_folds}folds'\n",
    "keep_false_positives_as_separate_test = True\n",
    "\n",
    "df_merged = pd.read_csv('/home/ubuntu/tenerife/data/LungAmbition/Excels_merged/LungAmbitionMergedAllGroupUpdated3mar2025.csv')\n",
    "# filter df_merged by GroupUpdated to keep only Lung_Cancer, Benign_Nodules and False_Positive\n",
    "df_merged = df_merged[df_merged['GroupUpdated'].isin(['Lung_Cancer', 'Benign_Nodules', 'False_Positive'])]\n",
    "df_merged = df_merged[['ID_proteinData', 'Group', 'Stage_category', 'NRRD_File', 'SEG_Files', 'Cancer_Status', 'TimeYears_CT_blood']]\n",
    "df_merged['SEG_Files'] = df_merged['SEG_Files'].apply(ast.literal_eval)\n",
    "if keep_false_positives_as_separate_test:\n",
    "    y_false_positives = df_merged[df_merged['Group'] == 'False_Positive']['Group']\n",
    "    # convert label to 1\n",
    "    y_false_positives = y_false_positives.replace({'False_Positive': 0})\n",
    "    ID_false_positives = df_merged[df_merged['Group'] == 'False_Positive']['ID_proteinData']\n",
    "    # create list to store wrong predicted false positives\n",
    "    list_ID_wrong_predicted_false_positives = []\n",
    "    X_false_positives = df_merged[df_merged['Group'] == 'False_Positive'].drop(columns=['ID_proteinData', 'Group'])\n",
    "    # drop in df_cur rows where Group is False_Positive\n",
    "    df_merged = df_merged[df_merged['Group'].isin(['Lung_Cancer', 'Benign_Nodules'])]\n",
    "    print(\"Number of false positives:\", X_false_positives.shape[0])\n",
    "    # save false_positive_metrics in df\n",
    "    false_positive_metrics = pd.DataFrame(columns=['AUC', 'Balanced_accuracy', 'Accuracy', 'Precision', 'Recall', 'F1-score'])\n",
    "else:\n",
    "    df_merged = df_merged[df_merged['Group'].isin(['Lung_Cancer', 'Benign_Nodules', 'False_Positive'])]\n",
    "    # print shape of excel\n",
    "    print(\"Dimensions excel after dropping rows where Group is False_Positive:\", df_merged.shape)\n",
    "\n",
    "# assert that Cancer_Status is 1 for patients where TimeYears_CT_blood is 0 and\n",
    "# Cancer_Status is 0 for patients where TimeYears_CT_blood is 5\n",
    "assert (df_merged.loc[df_merged[\"TimeYears_CT_blood\"] == 0, \"Cancer_Status\"] == 1).all(), \\\n",
    "    \"There are patients with TimeYears_CT_blood = 0 who do not have Cancer_Status = 1\"\n",
    "\n",
    "assert (df_merged.loc[df_merged[\"TimeYears_CT_blood\"] == 5, \"Cancer_Status\"] == 0).all(), \\\n",
    "    \"There are patients with TimeYears_CT_blood = 5 who do not have Cancer_Status = 0\"\n",
    "# define a new malignancy column, if Cancer_Status is 0, then malignancy is 0, else 1 according to proposed method\n",
    "df_merged['Malignancy'] = df_merged['Cancer_Status'].apply(lambda x: 0 if x == 0 else 1)\n",
    "# save best metrics for each fold\n",
    "fold_metrics_df = pd.DataFrame(columns=['Fold', 'Accuracy', 'Specificity', 'NPV', 'Precision', 'Recall', 'F1-score'])\n",
    "\n",
    "for fold in range(0, n_folds):\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Fold {fold + 1}:\")\n",
    "    # read train, test and val indices for each fold\n",
    "    fold_data = pd.read_csv(os.path.join(path_to_folds_csv, f'id2splitfold_{fold}.csv'))\n",
    "    train_index = fold_data[fold_data['split'] == 'train']['ID_proteinData']\n",
    "    test_index = fold_data[fold_data['split'] == 'test']['ID_proteinData']\n",
    "    val_index = fold_data[fold_data['split'] == 'val']['ID_proteinData']\n",
    "    # get first train, text, val, then split into X_train, X_test, X_val and y_train, y_test, y_val\n",
    "    train = df_merged.loc[df_merged['ID_proteinData'].isin(train_index)]\n",
    "    test = df_merged.loc[df_merged['ID_proteinData'].isin(test_index)]\n",
    "    val = df_merged.loc[df_merged['ID_proteinData'].isin(val_index)]\n",
    "    # print number of samples in train, val and test for Malignancy 0 and 1\n",
    "    print(\"Train, total benign nodules\", train[train['Malignancy'] == 0].shape[0], \"lung cancer\", train[train['Malignancy'] == 1].shape[0])\n",
    "    print(\"Val, total benign nodules\", val[val['Malignancy'] == 0].shape[0], \"lung cancer\", val[val['Malignancy'] == 1].shape[0])\n",
    "    print(\"Test, total benign nodules\", test[test['Malignancy'] == 0].shape[0], \"lung cancer\", test[test['Malignancy'] == 1].shape[0])\n",
    "    train_loader = load_lungAmbition(df_merged, batch_size=config_args.batch_size, spatial_size=[32, 32, 32], shuffle=False, type_processing = None)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = load_lungAmbition(train, batch_size=1, spatial_size=[64, 64, 64], shuffle=False, type_processing = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{'image': tensor([[[[[0.0286, 0.1157, 0.1779,  ..., 0.7593, 0.7786, 0.7279],\n",
      "           [0.1143, 0.0379, 0.0479,  ..., 0.5636, 0.6621, 0.7486],\n",
      "           [0.2129, 0.0121, 0.0571,  ..., 0.8457, 0.7393, 0.6757],\n",
      "           ...,\n",
      "           [0.1329, 0.2093, 0.1071,  ..., 0.0879, 0.0571, 0.0893],\n",
      "           [0.2357, 0.2036, 0.1479,  ..., 0.0307, 0.0279, 0.1771],\n",
      "           [0.1464, 0.1900, 0.0000,  ..., 0.0471, 0.0000, 0.0307]],\n",
      "\n",
      "          [[0.1371, 0.0071, 0.0414,  ..., 0.7393, 0.8793, 0.6457],\n",
      "           [0.0136, 0.0636, 0.0000,  ..., 0.6329, 0.7229, 0.6171],\n",
      "           [0.0450, 0.1836, 0.0136,  ..., 0.8550, 0.7929, 0.5729],\n",
      "           ...,\n",
      "           [0.2236, 0.0000, 0.1043,  ..., 0.1029, 0.1379, 0.0014],\n",
      "           [0.2243, 0.1136, 0.0850,  ..., 0.1571, 0.0679, 0.0236],\n",
      "           [0.1257, 0.0229, 0.0314,  ..., 0.0679, 0.0000, 0.0000]],\n",
      "\n",
      "          [[0.0450, 0.0529, 0.1143,  ..., 0.6443, 0.5529, 0.6679],\n",
      "           [0.0571, 0.0957, 0.1036,  ..., 0.8371, 0.7343, 0.8250],\n",
      "           [0.0607, 0.0893, 0.0586,  ..., 0.7300, 0.9371, 0.8486],\n",
      "           ...,\n",
      "           [0.0807, 0.1379, 0.0000,  ..., 0.2907, 0.3350, 0.0714],\n",
      "           [0.0700, 0.1014, 0.0057,  ..., 0.0714, 0.0507, 0.0000],\n",
      "           [0.0871, 0.0764, 0.0743,  ..., 0.0000, 0.1357, 0.0000]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0193, 0.0229, 0.0057,  ..., 0.0821, 0.0671, 0.0814],\n",
      "           [0.1064, 0.0000, 0.0000,  ..., 0.0093, 0.0507, 0.0000],\n",
      "           [0.0893, 0.0343, 0.0000,  ..., 0.1229, 0.1100, 0.0000],\n",
      "           ...,\n",
      "           [0.0436, 0.0000, 0.0000,  ..., 0.2557, 0.1657, 0.1514],\n",
      "           [0.1100, 0.1114, 0.1243,  ..., 0.0536, 0.0000, 0.0357],\n",
      "           [0.1450, 0.0729, 0.0000,  ..., 0.0221, 0.0700, 0.0000]],\n",
      "\n",
      "          [[0.0000, 0.0371, 0.0371,  ..., 0.1529, 0.0507, 0.1736],\n",
      "           [0.0143, 0.1150, 0.0793,  ..., 0.1329, 0.0936, 0.0564],\n",
      "           [0.0000, 0.0200, 0.0000,  ..., 0.1050, 0.0136, 0.0000],\n",
      "           ...,\n",
      "           [0.2314, 0.2536, 0.0664,  ..., 0.0100, 0.1543, 0.0000],\n",
      "           [0.1714, 0.0664, 0.0143,  ..., 0.0529, 0.0657, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0457,  ..., 0.0000, 0.0000, 0.0493]],\n",
      "\n",
      "          [[0.0779, 0.0000, 0.0000,  ..., 0.0000, 0.0957, 0.0000],\n",
      "           [0.0579, 0.0514, 0.1214,  ..., 0.0000, 0.0271, 0.0636],\n",
      "           [0.0050, 0.0457, 0.0443,  ..., 0.0079, 0.0000, 0.2479],\n",
      "           ...,\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0093, 0.0000, 0.1407],\n",
      "           [0.0543, 0.0000, 0.0486,  ..., 0.0000, 0.0164, 0.0279],\n",
      "           [0.0550, 0.0750, 0.0000,  ..., 0.1886, 0.1150, 0.0486]]]]],\n",
      "       dtype=torch.float64), 'seg': tensor([[[[[0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           ...,\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "          [[0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           ...,\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "          [[0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           ...,\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           ...,\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "          [[0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           ...,\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "          [[0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           ...,\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0]]]]], dtype=torch.int32), 'id': ['1122 (2011)'], 'mal': tensor([0]), 'seg_path': ['/home/ubuntu/tenerife/data/LungAmbition/LDCT_data/Benign_Nodules/1122/Baja dosis  1.0_SEG.nrrd']}\n"
     ]
    }
   ],
   "source": [
    "# print next iter in train_loader\n",
    "for i, data in enumerate(train_loader):\n",
    "    print(i)\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['image', 'seg', 'id', 'mal', 'seg_path'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 64, 64, 64])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 64, 64, 64])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['seg'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lungAmbpy3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
